Master Execution Plan: Life Story Game SaaSStrategy: Local Backend (Docker) â†” Remote Managed Database (DigitalOcean)This document outlines the exact step-by-step process to migrate from the stateless MVP to the stateful SaaS architecture.Prerequisites:DigitalOcean Managed Database: Ensure you have the connection string (e.g., postgresql://doadmin:password@host:port/defaultdb?sslmode=require).Trusted Sources: Add your current IP address to the DigitalOcean Database "Trusted Sources" list so you can connect locally.ðŸ—ï¸ Phase 1: Infrastructure & Connectivity (Start Here)Goal: A running backend that can talk to the remote database.Step 1.1: Backend Environment SetupCreate .env in the root directory (do NOT commit this file).DATABASE_URL="postgresql://doadmin:password@host:port/defaultdb?sslmode=require"
GEMINI_API_KEY="your_api_key"
Create docker-compose.yml (see file below). This defines your local backend service.Step 1.2: FastAPI FoundationCreate the core file structure:backend/app/main.py: The entry point for the API.backend/app/db/session.py: The database connection logic (SQLAlchemy).backend/app/db/base.py: The registry for models (critical for Alembic).backend/app/db/base_class.py: The base class for all models.Step 1.3: Verify ConnectivityRun the backend locally:docker-compose up --build
Success Criteria: You see "Application startup complete" logs and no database connection errors.ðŸ—„ï¸ Phase 2: Database Schema ImplementationGoal: Create the necessary tables in the remote database.Step 2.1: Define ModelsCreate backend/app/models/message.py. This defines the table structure for chat persistence.Step 2.2: Migration Setup (Alembic)Initialize Alembic: alembic init alembic.Edit alembic/env.py to import your Base from backend.app.db.base.Edit alembic.ini to point sqlalchemy.url to your .env variable (or use a script to inject it).Step 2.3: Run MigrationsGenerate and apply the schema:alembic revision --autogenerate -m "Initial tables"
alembic upgrade head
Success Criteria: Check your DigitalOcean database (using a tool like TablePlus or DBeaver). You should see the messages table created.ðŸ§  Phase 3: Logic Migration (The "Brain")Goal: Move Python logic from Vercel Functions to FastAPI.Step 3.1: Port Chat LogicMove logic from api/chat.py (Vercel) to backend/app/api/endpoints/chat.py (FastAPI).Remove http.server.BaseHTTPRequestHandler dependency.Use FastAPI request/response models.Critical Change: Instead of reading messages from the JSON body, read them from the Database using the session_id.Step 3.2: Implement EndpointsPOST /api/chat: Saves user message to DB -> Calls AI -> Streams response -> Saves AI response to DB.GET /api/history: Returns list of messages for the UI.ðŸŽ¨ Phase 4: Frontend Integration (Vertical Slice 1)Goal: Connect the React frontend to the new persistent backend.Step 4.1: Install TanStack Querycd frontend
npm install @tanstack/react-query
Step 4.2: Create Data HooksCreate frontend/src/hooks/useChat.js:useQuery for fetching message history.useMutation for sending messages.Step 4.3: Refactor App.jsxRemove the big useState messages array.Replace it with data from useChat.Point API calls to http://localhost:8000 (local) or your DO Droplet URL (production).ðŸš€ Phase 5: Production DeploymentGoal: Go live.Backend: Build the Docker image and push to DigitalOcean Container Registry. Deploy to App Platform or Droplet.Frontend: Update Vercel environment variable VITE_API_URL to point to the production backend URL. Redeploy.Immediate Action Item:Start with Phase 1, Step 1.1. I have generated the necessary files below.
